klimovic:
    name: 'Ana Klimovic (ETH Zurich)'
    title: 'Scalable Input Data Processing for Resource-Efficient Machine Learning' 
    abstract: 'Data is the lifeblood of machine learning. Yet, our system infrastructure for managing and preprocessing training data in ML jobs lags behind the vast advancements in hardware accelerators, software frameworks, and algorithms that optimize model training computations. The input data pipeline in an ML job is responsible for extracting data from storage, transforming data on-the-fly, and loading data to a training node (typically a GPU or TPU). As hardware accelerators continues to provide more FLOPS, feeding data at a sufficient rate to saturate accelerators is increasingly challenging. The high cost of accelerators compared to their CPU hosts makes it particularly important to ensure that they operate at high utilization. Hence, the input pipeline is critical to the end-to-end throughput and cost of ML jobs. In this talk, we will discuss the characteristics of real ML input pipelines from production workloads which have led to the trend of disaggregating input data processing from model training. I will present recent open-source systems such as tf.data service and Cachew, which leverage a disaggregated system architecture to scale-out and optimize data processing within and across jobs. These systems alleviate input bottlenecks and dramatically improve the training time and cost of ML jobs.' 
    bio1: "Ana Klimovic is an Assistant Professor in the Systems Group of the Computer Science Department at ETH Zurich. Her research interests span operating systems, computer architecture, and their intersection with machine learning. Ana's work focuses on computer system design for large-scale applications such as cloud computing services, data analytics, and machine learning. Before joining ETH in August 2020, Ana was a Research Scientist at Google Brain and completed her Ph.D. in Electrical Engineering at Stanford University."

hellerstein:
    name: 'Joseph M. Hellerstein (UC Berkeley)'
    title: 'Declaring the Era of Programmable Clouds'
    abstract: "For a decade or more, the main business of public cloud vendors has been to replace traditional enterprise computing systems with similar hosted services. This brought once-in-a-lifetime disruption to the business landscape. In comparison, the ambitions for innovation in cloud software engineering have been relatively modest. Given its revolutionary scale and potential, the cloud’s real impact on software innovation is likely yet to come. 

What are we waiting for? The main impediment seems to be the absence of a programming stack that unlocks the full power of the cloud for general-purpose programming and innovation at scale.

In this talk I will go over key concerns for cloud programming, opportunities to learn from the success of declarative languages, and concrete examples in systems work. We’ll begin with replication, reviewing the CALM Theorem and the Anna KVS; the former connecting a program property (monotonicity) to a runtime guarantee (consistency), the latter showing the power and limitations of CALM design in practice. In that frame, we’ll look at connections to data consistency and isolation levels. Moving beyond read/write semantics, we will use CRDTs as an entry point and anti-pattern for richer distributed programming models. Finally, we’ll shift attention to partitioning, using the lens of Functional Dependencies to scale concrete examples of classical protocols like Paxos.

Building on these results, I will overview Hydro, our nascent effort to develop a multi-level compiler stack a la LLVM, but one that is focused on distributed systems concerns. Challenges include architecting a low-latency asynchronous dataflow kernel for general-purpose services; IR designs that can leverage type-checkers like that of Rust for distributed properties; techniques to transpile (“lift”) sequential code to scalable alternatives; and the requirements for a compiler whose output is a live autoscaling service, not merely an executable.

Joint work with colleagues at UC Berkeley and Sutter Hill Ventures."
    bio1: "Joseph M. Hellerstein's work focuses on data-centric systems and the way they drive computing. He is the Jim Gray Professor of Computer Science at UC Berkeley, an ACM Fellow, an Alfred P. Sloan Research Fellow and the recipient of four \"Test of Time\" awards for his research. MIT's Technology Review magazine included his work on cloud programming in their TR10 list of the 10 technologies \"most likely to change our world\".

Hellerstein is also involved in the computing industry, currently as a Fellow at Sutter Hill Ventures and as co-founder of Aqueduct, which is developing new open source cloud technology for Prediction Infrastructure. Previously he co-founded Trifacta, the pioneering company in Data Preparation."
    
olukotun:
    name: 'Kunle Olukotun (Stanford University)'
    title: 'Systems for ML and ML for Systems:  A Virtuous Cycle'
    abstract: "This talk is about the virtuous interplay between machine learning (ML) and systems. I will show examples of how systems optimized for ML computation can be used to train more accurate and capable ML models and how these ML models can be used to improve upon the ad-hoc heuristics used in system design and management. These improved systems can then be used to train better ML models. The latest trend in ML is the development of Foundation models. Foundation models are large pretrained models that have obtained state-of-the-art quality in natural language processing, vision, speech, and other areas. These models are challenging to train and serve because they are characterized by billions of parameters, irregular data access (sparsity) and irregular control flow. I will explain how Reconfigurable Dataflow Accelerators (RDAs) can be designed to accelerate foundation models with these characteristics. SambaNova Systems is using RDA technology to achieve record-setting performance on foundation models.  I will describe how the RDAs can also be used to build Taurus, an intelligent network data plane that enables ML models to be used to manage computer networks at full line-rate bandwidths. In particular, a Taurus prototype detects two orders of magnitude more events in a security application than a state-of-the-art system based on conventional network technology."
    bio1: "Kunle Olukotun is the Cadence Design Professor of Electrical Engineering and Computer Science at Stanford University. Olukotun is a pioneer in multicore processor design and the leader of the Stanford Hydra chip multiprocessor (CMP) research project. He founded Afara Websystems to develop high-throughput, low-power multicore processors for server systems. The Afara multi-core processor, called Niagara, was acquired by Sun Microsystems and now powers Oracle's SPARC-based servers. In 2017, Olukotun co-founded SambaNova Systems, a Machine Learning and Artificial Intelligence company, and continues to lead as their Chief Technologist. Olukotun is the Director of the Pervasive Parallel Lab and a member of the Data Analytics tor What's Next (DAWN) Lab, developing infrastructure for usable machine learning. He is a member of the National Academy of Engineering, an ACM Fellow, and an IEEE Fellow for contributions to multiprocessors on a chip design and the commercialization of this technology. He also received the Harry H. Goode Memorial Award.  Olukotun received his Ph.D. in Computer Engineering from The University of Michigan."

akella:
  name: 'Aditya Akella (UT Austin)'
  title: 'Networking and Cloud: A Match Made in Heaven'
  abstract: "Over the past few years, networking advances have spurred fundamental transformations in cloud computing. Technologies such as software defined networking, network virtualization, and high-bisection fabrics have simplified cloud design and operation, brought exciting new workloads to the cloud, and helped lower the bar to cloud adoption. Networking is poised to bring even more interesting and fundamental transformations to the cloud over the next few years. In this talk, I will describe several promising networking ideas, spanning high-performance fabrics and network stacks, programmable hardware, abstractions for network automation, and novel inter-domain protocols and services. I will discuss the tantalizing opportunities these ideas  offer for cloud computing, and the fundamental new research and practical challenges they introduce. I will conclude my talk with observations on what it would take for our research community to make rapid and meaningful progress in this space."
  bio1: "Aditya Akella is a Regents Chair Professor of Computer Science at UT Austin and a software engineer at Google. Aditya received his B. Tech. from IIT Madras (2000), and PhD from CMU (2005). His research spans computer systems and networking, with a focus on programmable networks, formal methods in systems, and systems for big data and machine learning. His work has influenced the infrastructure of some of the world’s largest online service providers. Aditya has received many awards for his contributions, including being selected as a finalist for the US Blavatnik National Award for Young Scientists (2020 and 2021), UW-Madison “Professor of the Year” award (2019 and 2017), IRTF Applied Networking Research Prize (2015), SIGCOMM Rising Star award (2014), NSF CAREER award (2008), and several best paper awards."
  
bailis:
  name: 'Peter Bailis (Sisu Data)'
  title: 'The Future of Cloud Data: Challenges and Research Opportunities'
  abstract: "The last several years have seen the creation of hundreds of billions of dollars in market value – including the largest software IPO of all time – centered around one technology category: cloud data. While cloud data is not new, the rate of adoption across almost every industry and the associated pace of development around all aspects of cloud data (from pipelines to extract-load-transform (ELT) tools to storage and analytics) are unprecedented. In this talk, I’ll present a research-oriented perspective on the future of cloud data that combines my experiences as an academic at Stanford and as a startup founder and CEO at Sisu Data. My goal is to provide an overview of the seismic changes in the cloud data landscape that – in my opinion – have yet to receive sufficient attention from research, and to highlight several tantalizing research opportunities in systems and databases that result."
  bio1: "Peter is the CEO and Founder of Sisu Data. Before Sisu, Peter was an assistant professor of Computer Science at Stanford University, where he maintains an adjunct appointment. Peter received a Ph.D. from UC Berkeley and an A.B. from Harvard College, both in Computer Science."
 
bhagwan:
  name: 'Ranjita Bhagwan (Microsoft Research)'
  title: 'Leveraging Data to Improve Cloud Services'
  abstract: "Today’s cloud services are large, complex, and dynamic, often supporting billions of users.  Such a complex and dynamic environment poses several challenges such as ensuring fast and secure development and deployment, and prompt resolution of service disruptions. Nevertheless, new opportunities to address such challenges have emerged. Large-scale services generate petabytes of code, test, and usage-related data within just one day. This data can be harnessed to provide valuable insights to engineers on how to improve service performance, security and reliability. However, cherry-picking important information from such vast amounts of systems-related data proves to be a formidable task. Over the last few years, we have developed many analysis tools that leverage code, test logs and telemetry to address these challenges. In this talk, I will talk about our experience with building such tools, and describe our journey which started with determining the right problems to solve, making research contributions and ended with widespread deployment across Microsoft’s services."
  bio1: "Ranjita Bhagwan is Senior Principal Researcher at Microsoft Research India. She has worked for more than a decade on applying machine learning to improve system reliability, security and performance. Recently, her work has focused on using data-driven approaches to improve cloud services and has led to several publications (including a best paper award at OSDI 2018), as well as several tools that are widely used by Microsoft’s services. She is the recipient of the 2020 ACM India Outstanding Contributions to Computing by a Woman Award and has chaired multiple top conferences in the fields of systems and networking. Ranjita received her PhD and MS in Electrical and Computer Engineering from University of California, San Diego and a BTech in Computer Science and Engineering from the Indian Institute of Technology, Kharagpur."
  
svore:
  name: ' Krysta Svore (Microsoft)'
  title: 'Accelerating the cloud with quantum'
  abstract: "Azure Quantum.  The power of Azure, accelerated by Quantum.  This is the present and future of cloud computing.  A quantum-classical compute fabric that holds the promise of helping to remake our global economy, by offering new capabilities to help solve some of our planet’s biggest challenges—in energy, climate, agriculture, and health—and across a broad span of industrial sectors, including computational chemistry, materials science, and nuclear and particle physics.  Quantum computers are accelerators to large-scale classical compute and receive instructions and cues from classical processors.  The success of quantum computation requires seamless integration in a high-performance cloud, to enable hyperscale workloads with complex classical pre- and post-processing.  It also requires scaling up; to achieve the full promise, we need a leadership-class quantum machine with more than 1M physical qubits. I’ll share the types of problems such a quantum machine will accelerate in the cloud, and how you can program and develop towards these advances today with Azure Quantum.  I’ll also share how quantum ideas are being emulated to enhance classical solutions, enabling quantum impact right now.   Welcome to the quantum era of computing."
  bio1: "Dr. Krysta Svore is General Manager of Quantum Systems at Microsoft. She believes empowering people with the power of quantum computing, today and tomorrow, will be one of the greatest revolutionary steps in our history. She leads a team dedicated to realizing a commercial-scale quantum computing system and ecosystem to solve today’s unsolvable problems. She spent her early years at Microsoft developing machine-learning methods for web applications, including ranking, classification, and summarization algorithms. In 2018, Dr. Svore was named one of the 39 Most Powerful Women Engineers according to Business Insider. Dr. Svore serves as a member of the Advanced Scientific Computing Advisory Committee of the Department of Energy and as a member of the ISAT Committee of DARPA.  She is an appointee of the National Quantum Initiative Advisory Committee.  She has received an ACM Best of 2013 Notable Article award and was a member of the winning team of the Yahoo! Learning to Rank Challenge in 2010. She chaired the 2017 Quantum Information Processing Conference. Dr. Svore is a Kavli Fellow of the National Academy of Sciences, a Senior Member of the Association for Computing Machinery (ACM), a representative for the Academic Alliance of the National Center for Women and Information Technology (NCWIT), and a member of the American Physical Society (APS). Dr. Svore has authored over 70 papers and has filed over 25 patents. She received her PhD in computer science with highest distinction from Columbia University and her BA from Princeton University in Mathematics with a minor in Computer Science and French."
  
